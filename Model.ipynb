{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a11b1bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T08:56:04.931983Z",
     "start_time": "2025-01-13T08:56:04.913030Z"
    },
    "id": "initial_id"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 09:00:15.061536: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-02 09:00:15.074015: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743584415.087449 2984266 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743584415.091287 2984266 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-02 09:00:15.105893: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import random\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dropout, Conv2D, MaxPooling2D, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a75c539d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "77051fda-568d-4ce5-be68-5d6460520f59",
    "outputId": "76fffadc-afab-49f8-9e95-5dc7eedcac3d"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Get the list of all physical GPUs\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# Select only the last GPU (index 7)\n",
    "if len(physical_devices) >= 2:\n",
    "    try:\n",
    "        # Set only the last GPU as visible\n",
    "        tf.config.set_visible_devices(physical_devices[1], 'GPU')\n",
    "        # Optional: Limit GPU memory growth (prevents TensorFlow from allocating all memory)\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[1], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error while setting GPU configuration: {e}\")\n",
    "else:\n",
    "    print(\"Insufficient GPUs available.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a131a2b3",
   "metadata": {
    "id": "4cc350b94ceef1c8"
   },
   "source": [
    "\n",
    "Create custom Effnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6c62706",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T10:27:10.767765Z",
     "start_time": "2025-01-13T10:27:10.759544Z"
    },
    "id": "6eb089a40e4e24b3"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import random\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dropout, Conv2D, MaxPooling2D, BatchNormalization\n",
    "# from keras.activations import silu\n",
    "class TMCViTReplacement(keras.Model):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        channel_size, seq_len = config['Data_shape'][1], config['Data_shape'][2]\n",
    "        self.emb_size = config['emb_size']  # d_x (input embedding dimension)\n",
    "        self.patch_size = 4  # Ensuring appropriate patching\n",
    "        self.num_patches = seq_len // self.patch_size\n",
    "        self.projection_dim = self.emb_size\n",
    "        self.num_heads = 4\n",
    "        self.transformer_units = [self.projection_dim * 2, self.projection_dim]\n",
    "        self.transformer_layers = 8\n",
    "        self.token_emb = keras.Sequential([\n",
    "            layers.Conv2D(16, (channel_size, 1), activation=\"relu\", padding=\"valid\", data_format='channels_first'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling2D((1, config['pooling_size']), data_format='channels_first'),\n",
    "            layers.Conv2D(32, (16, 3), activation=\"relu\", padding=\"same\", data_format='channels_first'),  # Reduce channels\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Conv2D(1, (32, 3), activation=\"relu\", padding=\"same\", data_format='channels_first'),  # Output 1 channel\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Conv2D(self.emb_size, (1, 1), activation=\"relu\", padding=\"valid\", data_format='channels_first'),  # Ensure emb_size in the right dimension\n",
    "            layers.BatchNormalization(),\n",
    "\n",
    "        ])\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.patch_encoder = layers.Dense(units=self.projection_dim)\n",
    "        self.position_embedding = layers.Embedding(input_dim=self.num_patches, output_dim=self.projection_dim)\n",
    "        self.norm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.attention_layer = layers.MultiHeadAttention(\n",
    "            num_heads=self.num_heads, key_dim=self.projection_dim, dropout=0.1\n",
    "        )\n",
    "        self.mlp_layers = [layers.Dense(unit, activation=tf.nn.gelu) for unit in self.transformer_units]\n",
    "        self.dropout = layers.Dropout(0.1)\n",
    "        self.transformer_blocks = [\n",
    "            layers.LayerNormalization(epsilon=1e-6),\n",
    "            layers.MultiHeadAttention(num_heads=self.num_heads, key_dim=self.projection_dim, dropout=0.1),\n",
    "            layers.LayerNormalization(epsilon=1e-6),\n",
    "            layers.Dense(self.transformer_units[0], activation=tf.nn.gelu),\n",
    "            layers.Dense(self.transformer_units[1], activation=tf.nn.gelu),\n",
    "        ]\n",
    "\n",
    "        self.mlp_head = keras.Sequential([\n",
    "            layers.LayerNormalization(epsilon=1e-6),\n",
    "            layers.Dense(2048, activation=tf.nn.gelu),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(self.projection_dim, activation=tf.nn.gelu),\n",
    "            layers.Dropout(0.5),\n",
    "        ])\n",
    "        \n",
    "    def mlp(self, x):\n",
    "        for layer in self.mlp_layers:\n",
    "            x = layer(x)\n",
    "        return self.dropout(x)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = tf.expand_dims(x, axis=1)  # (bs, 1, channels, seq_len)\n",
    "        x = self.token_emb(x)  # (bs, 1, emb_size, seq_len // pooling)\n",
    "        x = tf.transpose(x, [0, 2, 1, 3])\n",
    "        x = tf.squeeze(x, axis=1)  # (bs, emb_size, seq_len // pooling)\n",
    "        x = tf.transpose(x, perm=[0, 2, 1])  # (bs, seq_len // pooling, emb_size)\n",
    "        encoded_patches = self.patch_encoder(x) + self.position_embedding(tf.range(x.shape[1]))\n",
    "        for _ in range(self.transformer_layers):\n",
    "            # Layer normalization 1.\n",
    "            x1 = self.norm1(encoded_patches)\n",
    "            # Create a multi-head attention layer.\n",
    "            attention_output = self.attention_layer(x1, x1)\n",
    "            # Skip connection 1.\n",
    "            x2 = layers.Add()([attention_output, encoded_patches])\n",
    "            # Layer normalization 2.\n",
    "            x3 = self.norm2(x2)\n",
    "            # MLP.\n",
    "            x3 = self.mlp(x3)\n",
    "            # Skip connection 2.\n",
    "            encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "        return self.mlp_head(encoded_patches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7ee2cd5",
   "metadata": {
    "id": "29aa494fdaef5e57"
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(keras.Model):\n",
    "    def __init__(self, max_len, d_model):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "\n",
    "        position = tf.range(0, max_len, dtype=tf.float32)[:, tf.newaxis]  # Shape: (max_len, 1)\n",
    "        div_term = tf.exp(- (tf.range(0, d_model, 2, dtype=tf.float32) *\n",
    "                             -(np.log(10000.0) / d_model)))  # Shape: (d_model // 2,)\n",
    "\n",
    "        # Expand div_term to align with position for broadcasting\n",
    "        div_term = tf.expand_dims(div_term, 0)  # Shape: (1, d_model // 2)\n",
    "\n",
    "        pe = tf.concat(\n",
    "            [tf.sin(position * div_term), tf.cos(position * div_term)],\n",
    "            axis=1\n",
    "        )  # Shape: (max_len, d_model)\n",
    "\n",
    "        # Pad if d_model is odd\n",
    "        if d_model % 2 != 0:\n",
    "            pe = tf.concat([pe, tf.zeros((max_len, 1), dtype=tf.float32)], axis=1)\n",
    "\n",
    "        pe = tf.expand_dims(pe, axis=0)\n",
    "        self.pe = tf.Variable(pe, trainable=False)\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.pe[:, :tf.shape(x)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7957b6f",
   "metadata": {
    "id": "c1b91bfb-736d-4528-8a66-2cf7d451466c"
   },
   "outputs": [],
   "source": [
    "def Semantic_Subsequence_Preserving(time_step_indices, chunk_count, target_percentage):\n",
    "    # Get the total number of time steps\n",
    "    total_time_steps = len(time_step_indices) # var=512\n",
    "    # Calculate the desired total time steps for the selected chunks\n",
    "    target_total_time_steps = int(total_time_steps * target_percentage) #256\n",
    "\n",
    "    # Calculate the size of each chunk\n",
    "    chunk_size = target_total_time_steps // chunk_count #128\n",
    "\n",
    "    # Randomly select starting points for each chunk with minimum distance\n",
    "    start_points = [random.randint(0, total_time_steps - chunk_size)] #(0,384)\n",
    "    # Randomly select starting points for each subsequent chunk with minimum distance\n",
    "    for _ in range(chunk_count - 1):\n",
    "        next_start_point = random.randint(0, total_time_steps - chunk_size)\n",
    "        start_points.append(next_start_point)\n",
    "\n",
    "    # Select non-overlapping chunks using indices\n",
    "    selected_chunks_indices = [time_step_indices[start:start + chunk_size] for start in start_points]\n",
    "\n",
    "    return selected_chunks_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81d06b5",
   "metadata": {
    "id": "b6f8d0f4-85e9-4f45-8e81-d0f46b3e820a"
   },
   "source": [
    "Add Attention.py TransformerBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d38bafa",
   "metadata": {
    "id": "b76d72b1-c2b0-4004-9828-06a5774ebe95"
   },
   "outputs": [],
   "source": [
    "class Attention(keras.Model):\n",
    "    def call(self, query, key, value, mask=None, dropout=None, training=None):\n",
    "        #print(f' shapes received:\\n query={query.shape}\\n key={key.shape}\\n value={value.shape}\\n mask={mask.shape}')\n",
    "        d_k = tf.cast(tf.shape(query)[-1], tf.float32) #Casting the last value of shape into float for division in the next line\n",
    "        scores = tf.matmul(query, key, transpose_b=True) / tf.math.sqrt(d_k) #transpose will swap the last 2 dims of the key matrix\n",
    "        if mask is not None:\n",
    "            mask = tf.cast(mask, tf.float32)\n",
    "            scores += (mask * -1e9)  # Masking with a very negative value\n",
    "        p_attn = tf.nn.softmax(scores, axis=-1)\n",
    "        if dropout is not None:\n",
    "            p_attn = dropout(p_attn, training=training)\n",
    "        return tf.matmul(p_attn, value),p_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ee570d",
   "metadata": {
    "id": "d1b98d22-2d19-4e78-8043-7dbf797f18da"
   },
   "source": [
    "Add attention.py Multihead Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a09f1a9",
   "metadata": {
    "id": "e738d885-a664-4dbd-a319-495d56559490"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(keras.Model):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "\n",
    "        # Below Assumption by the authors\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "\n",
    "        self.linear_layers = [keras.layers.Dense(d_model) for _ in range(3)]\n",
    "        self.output_linear = keras.layers.Dense(d_model)\n",
    "        self.attention = Attention()\n",
    "        self.dropout = keras.layers.Dropout(rate=dropout)\n",
    "\n",
    "    def call(self, query, key, value, mask=None, training=None):\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        query, key, value = [\n",
    "            tf.transpose(tf.reshape(l(x), (batch_size, -1, self.h, self.d_k)), perm=[0, 2, 1, 3])\n",
    "            for l, x in zip(self.linear_layers, (query, key, value))\n",
    "        ]\n",
    "\n",
    "        # 2) Apply attention on all the projected vectors in batch.\n",
    "        x, attn = self.attention(query, key, value, mask=mask, dropout=self.dropout, training=training)\n",
    "\n",
    "        # 3) \"Concat\" using a view and apply a final linear.\n",
    "        x = tf.transpose(x, (0, 2, 1, 3))\n",
    "        x = tf.reshape(x, (batch_size, -1, self.h * self.d_k))\n",
    "\n",
    "        return self.output_linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7277b016",
   "metadata": {
    "id": "8jqFd_TgFjbq"
   },
   "source": [
    "Add Attention.py PointWiseFeedForward\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7aa8c8e1",
   "metadata": {
    "id": "8d73c857-d6e7-4baf-8066-0a005806ecf6"
   },
   "outputs": [],
   "source": [
    "class PointWiseFeedForward(keras.Model):\n",
    "    def __init__(self, d_model, d_ffn, dropout=0.1):\n",
    "        super(PointWiseFeedForward, self).__init__()\n",
    "        self.linear1 = keras.layers.Dense(d_ffn, input_shape=(d_model,))\n",
    "        self.linear2 = keras.layers.Dense(d_model, input_shape=(d_ffn,))\n",
    "        self.activation = keras.activations.gelu\n",
    "        self.dropout = keras.layers.Dropout(rate=dropout)\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        return self.dropout(self.linear2(self.activation(self.linear1(x))), training=training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d857d3db",
   "metadata": {
    "id": "4Q4W-XXPG_YD"
   },
   "source": [
    "Add Attention.py SublayerConnection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d6e276f",
   "metadata": {
    "id": "0ca01846-0aa0-4aa2-8460-e27c9a2e5b8b"
   },
   "outputs": [],
   "source": [
    "class SublayerConnection(keras.Model):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, enable_res_parameter, dropout=0.1):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = keras.layers.LayerNormalization(axis=-1, epsilon=1e-6)\n",
    "        self.dropout = keras.layers.Dropout(rate=dropout)\n",
    "        self.enable = enable_res_parameter\n",
    "        if enable_res_parameter:\n",
    "            self.a = tf.Variable(1e-8, trainable=True, dtype=tf.float32)\n",
    "\n",
    "    def call(self, x, sublayer, training=None):\n",
    "        if isinstance(x, list):\n",
    "            return self.norm(x[1] + self.dropout(self.a * sublayer(x, training=training), training=training))\n",
    "        if not self.enable:\n",
    "            return self.norm(x + self.dropout(sublayer(x, training=training), training=training))\n",
    "        else:\n",
    "            return self.norm(x + self.dropout(self.a * sublayer(x, training=training), training=training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79c9b8b8",
   "metadata": {
    "id": "rm5ASJ2bNWFb"
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(keras.Model):\n",
    "    \"\"\"\n",
    "    TRM layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, attn_heads, d_ffn, enable_res_parameter, dropout=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attn = MultiHeadAttention(attn_heads, d_model, dropout)\n",
    "        self.ffn = PointWiseFeedForward(d_model, d_ffn, dropout)\n",
    "        self.skipconnect1 = SublayerConnection(d_model, enable_res_parameter, dropout)\n",
    "        self.skipconnect2 = SublayerConnection(d_model, enable_res_parameter, dropout)\n",
    "\n",
    "    def call(self, x, mask, training=None):\n",
    "        # Pass training argument directly to sublayer function\n",
    "        def attn_sublayer(_x, training):\n",
    "            return self.attn(_x, _x, _x, mask=mask, training=training)\n",
    "        x = self.skipconnect1(x, sublayer=(attn_sublayer), training=training)\n",
    "        x = self.skipconnect2(x, sublayer=(self.ffn), training=training)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecb64c4",
   "metadata": {
    "id": "Yg-9_8hVdhwe"
   },
   "source": [
    "Encoder class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23500e70",
   "metadata": {
    "id": "__v7_4PRZwnd"
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable(package=\"Custom\")\n",
    "class Encoder(keras.Model):\n",
    "    def __init__(self, config):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.config = config  # Store config for use in get_config\n",
    "        d_model = config['emb_size']\n",
    "        attn_heads = config['num_heads']\n",
    "        # d_ffn = 4 * d_model\n",
    "        d_ffn = config['dim_ff']\n",
    "        layers = config['layers']\n",
    "        dropout = config['dropout']\n",
    "        enable_res_parameter = True\n",
    "        # TRMs\n",
    "        self.TRMs = [\n",
    "            TransformerBlock(d_model, attn_heads, d_ffn, enable_res_parameter, dropout)\n",
    "            for _ in range(layers)\n",
    "        ]\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        for TRM in self.TRMs:\n",
    "            x = TRM(x, mask=None, training=training)\n",
    "        return x\n",
    "\n",
    "        # def call(self, x, training=None):\n",
    "        # for TRM in self.TRMs:\n",
    "        #     x = TRM(x, mask=None, training=training)\n",
    "        # return x\n",
    "\n",
    "    def get_config(self):\n",
    "        # Save configuration for reconstruction\n",
    "        return {\"config\": self.config}\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        # Recreate the Encoder using the saved configuration\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d8305b",
   "metadata": {
    "id": "Xq2SRnt8g2-g"
   },
   "source": [
    "Add attention.py CrossAttnTRMBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cfaf8b8",
   "metadata": {
    "id": "-eqAH7ZfgGFP"
   },
   "outputs": [],
   "source": [
    "class CrossAttnTRMBlock(keras.Model):\n",
    "    def __init__(self, d_model, attn_heads, d_ffn, enable_res_parameter, dropout=0.1):\n",
    "        super(CrossAttnTRMBlock, self).__init__()\n",
    "        self.attn = MultiHeadAttention(attn_heads, d_model, dropout)\n",
    "        self.ffn = PointWiseFeedForward(d_model, d_ffn, dropout)\n",
    "        self.skipconnect1 = SublayerConnection(d_model, enable_res_parameter, dropout)\n",
    "        self.skipconnect2 = SublayerConnection(d_model, enable_res_parameter, dropout)\n",
    "\n",
    "    def call(self, rep_visible, rep_mask_token, mask=None, training=None):\n",
    "        x = [rep_visible, rep_mask_token]\n",
    "        def attn_sublayer(_x, training):\n",
    "            return self.attn(_x[1], _x[0], _x[0], mask=mask, training=training)\n",
    "        x = self.skipconnect1(x, sublayer=(attn_sublayer), training=training)\n",
    "        x = self.skipconnect2(x, sublayer=(self.ffn), training=training)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb4199f5",
   "metadata": {
    "id": "6XQEcKGvmUhY"
   },
   "outputs": [],
   "source": [
    "class Predictor(keras.Model):\n",
    "    def __init__(self, d_model, attn_heads, d_ffn, enable_res_parameter, num_layers):\n",
    "        super(Predictor, self).__init__()\n",
    "        self.num_layers = [\n",
    "            CrossAttnTRMBlock(d_model, attn_heads, d_ffn, enable_res_parameter,)\n",
    "            for _ in range(num_layers)\n",
    "        ]\n",
    "\n",
    "    def call(self, rep_visible, rep_mask_token, training=None):\n",
    "        for TRM in self.num_layers:\n",
    "            rep_mask_token = TRM(rep_visible, rep_mask_token)\n",
    "        return rep_mask_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00407e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from fastdtw import fastdtw\n",
    "\n",
    "def dtw_metric(y_true, y_pred):\n",
    "    def compute_dtw(y_true, y_pred):\n",
    "        distance, _ = fastdtw(y_true.numpy(), y_pred.numpy())\n",
    "        return np.float32(distance)\n",
    "\n",
    "    return tf.py_function(compute_dtw, [y_true, y_pred], tf.float32)\n",
    "\n",
    "def pcc_metric(y_true, y_pred):\n",
    "    x = y_true - tf.reduce_mean(y_true)\n",
    "    y = y_pred - tf.reduce_mean(y_pred)\n",
    "    r_num = tf.reduce_sum(x * y)\n",
    "    r_den = tf.sqrt(tf.reduce_sum(tf.square(x)) * tf.reduce_sum(tf.square(y)))\n",
    "    return r_num / (r_den + tf.keras.backend.epsilon())\n",
    "\n",
    "def cosine_similarity_metric(y_true, y_pred):\n",
    "    y_true = tf.nn.l2_normalize(y_true, axis=-1)\n",
    "    y_pred = tf.nn.l2_normalize(y_pred, axis=-1)\n",
    "    return tf.reduce_mean(tf.reduce_sum(y_true * y_pred, axis=-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da224a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_label(arr):\n",
    "    return arr[:,71,:][:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "407d57e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = np.load('stacked_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a45a925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17. 18.\n",
      " 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8020,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.unique(make_label(train_data)))\n",
    "make_label(train_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bb8fc0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600e81ff43f64d1aac4bc26b564ccf4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/364 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2bd4506c0714305853aa9067262c6ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/648 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "698c0677d456429facf27c440cf3fa5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/242k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1c87781ce3e4299b6ccd3ebb060254d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/480k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743584523.402211 2984266 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 77635 MB memory:  -> device: 1, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:43:00.0, compute capability: 9.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "from tensorflow.keras.layers import Input, Dense, LayerNormalization, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Enable mixed precision training\n",
    "# tf.keras.mixed_precision.set_global_policy('mixed_float32')\n",
    "\n",
    "# Load and preprocess data\n",
    "# val_repr = np.load(\"train_repr_VIT.npy\")\n",
    "val_repr_labels = make_label(train_data)\n",
    "sentence_data = pd.read_csv('Spanish.csv')\n",
    "#                             , encoding='latin-1')\n",
    "sentence_dict = dict(zip(sentence_data['ID'], sentence_data['Sentence (Spanish)']))\n",
    "y_sentences = [sentence_dict[sid] for sid in val_repr_labels]\n",
    "\n",
    "# Tokenization setup with Spanish BERT\n",
    "MODEL_NAME = \"dccuchile/bert-base-spanish-wwm-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenized = tokenizer(y_sentences, padding='max_length', truncation=True, return_tensors=\"tf\")\n",
    "\n",
    "# Convert to TensorFlow datasets\n",
    "# X_eeg = tf.convert_to_tensor(val_repr, dtype=tf.float32)\n",
    "y_input_ids = tf.convert_to_tensor(tokenized[\"input_ids\"], dtype=tf.int32)\n",
    "y_attention_mask = tf.convert_to_tensor(tokenized[\"attention_mask\"], dtype=tf.int32)\n",
    "\n",
    "# Get sequence parameters\n",
    "max_seq_len = y_input_ids.shape[1]\n",
    "vocab_size = tokenizer.vocab_size\n",
    "\n",
    "def build_eeg_to_text_model():\n",
    "    eeg_input = Input(shape=(1375,), name=\"eeg_input\")\n",
    "    \n",
    "    # Projection to BERT's space\n",
    "    x = LayerNormalization()(eeg_input)\n",
    "    x = Dense(768 * max_seq_len, activation='tanh')(x)\n",
    "    x = Reshape((max_seq_len, 768))(x)\n",
    "    \n",
    "    # Load BERT with correct expectations\n",
    "    bert = TFAutoModel.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        output_loading_info=False  # Suppress warnings\n",
    "          # Sometimes helps with compatibility\n",
    "    )\n",
    "    \n",
    "    # Get encoder outputs\n",
    "    encoder_outputs = bert(input_ids = None, inputs_embeds=tf.cast(x, tf.float32), training=False).last_hidden_state\n",
    "    \n",
    "    # Add task-specific head\n",
    "    logits = Dense(vocab_size)(encoder_outputs)\n",
    "    model = Model(inputs=eeg_input, outputs=logits)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5, clipnorm=1.0)\n",
    "    model.compile(optimizer=optimizer, loss=masked_loss, weighted_metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Masked loss function handling BERT's padding token (0)\n",
    "def masked_loss(y_true, y_pred):\n",
    "    loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)\n",
    "    mask = tf.cast(y_true != tokenizer.pad_token_id, tf.float32)\n",
    "    return tf.reduce_sum(loss * mask) / tf.reduce_sum(mask)\n",
    "def masked_accuracy(y_true, y_pred):\n",
    "    y_pred = tf.argmax(y_pred, axis=-1)\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    mask = tf.cast(y_true != tokenizer.pad_token_id, y_pred.dtype)\n",
    "    matches = tf.cast(y_pred == y_true, y_pred.dtype) * mask\n",
    "    accuracy = tf.reduce_sum(matches) / tf.maximum(tf.reduce_sum(mask), 1)\n",
    "    return accuracy\n",
    "# Build and compile the model\n",
    "\n",
    "\n",
    "# Training callbacks\n",
    "callbacks = [\n",
    "#     tf.keras.callbacks.TerminateOnNaN(),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=2),\n",
    "#     tf.keras.callbacks.ModelCheckpoint('ViT_bert_emb1024_tuned.keras', save_best_only=True, save_weights_only=True)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7481c7d",
   "metadata": {
    "id": "RiNvYLxn-ckY"
   },
   "source": [
    "EEG2Rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a658b874",
   "metadata": {
    "id": "TMjfA-ri9p8P"
   },
   "outputs": [],
   "source": [
    "class EEG2Rep(keras.Model):\n",
    "    def __init__(self, config, num_classes):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "         channel_size: number of EEG channels\n",
    "         seq_len: number of timepoints in a window\n",
    "        \"\"\"\n",
    "        # Parameters Initialization -----------------------------------------------\n",
    "        channel_size, seq_len = config['Data_shape'][1], config['Data_shape'][2]\n",
    "        emb_size = config['emb_size']  # d_x\n",
    "        # Embedding Layer -----------------------------------------------------------\n",
    "        seq_len = int(seq_len / config['pooling_size'])  # Number of patches (l)\n",
    "        self.ViT = TMCViTReplacement(config)  # input (Batch,Channel, length) -> output (Batch, l, d_x)\n",
    "        self.PositionalEncoding = PositionalEmbedding(seq_len, emb_size)\n",
    "        # -------------------------------------------------------------------------\n",
    "        self.summary_writer = tf.summary.create_file_writer('logs/ViT_bert_emb1024_pre')\n",
    "        self.momentum = config['momentum']\n",
    "        self.device = config['device']\n",
    "        self.mask_ratio = config['mask_ratio']\n",
    "        self.mask_len = int(config['mask_ratio'] * seq_len)\n",
    "        self.mask_token = self.add_weight(\n",
    "            shape=(emb_size,), initializer=\"random_normal\", trainable=True, name=\"mask_token\"\n",
    "        )\n",
    "        self.contex_encoder = Encoder(config)\n",
    "        self.target_encoder = copy.deepcopy(self.contex_encoder)\n",
    "        self.Predictor = Predictor(emb_size, config['num_heads'], config['dim_ff'], 1, config['pre_layers'])\n",
    "        self.predict_head = keras.layers.Dense(config['num_labels'])\n",
    "        self.Norm = keras.layers.LayerNormalization()\n",
    "        self.Norm2 = keras.layers.LayerNormalization()\n",
    "        self.gap = keras.layers.GlobalAveragePooling1D()\n",
    "        self.lambda_ = config['lambda']\n",
    "        self.mu = config['mu']\n",
    "        self.gamma = config['gamma']\n",
    "        self.mae_metric = tf.keras.metrics.MeanAbsoluteError()\n",
    "        self.dtw = dtw_metric\n",
    "        self.pcc_met = pcc_metric\n",
    "        self.cosine_sim = cosine_similarity_metric\n",
    "        self.bert = build_eeg_to_text_model()\n",
    "        # Create a projection layer to map our EEG representation to the input shape expected by BERT.\n",
    "        # (The BERT branch expects inputs of shape (1375,), so we project to that dimension.)\n",
    "        self.downstream_projection = keras.layers.Dense(1375)\n",
    "        # Mode: set externally to either \"pretrain\" or \"downstream\".\n",
    "        self.mode = \"downstream\"\n",
    "        # Add accuracy metrics\n",
    "        self.train_acc = tf.keras.metrics.Mean(name=\"train_accuracy\")\n",
    "        self.val_acc = tf.keras.metrics.Mean(name=\"val_accuracy\")\n",
    "        \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # Include the compiled metrics and the custom metrics\n",
    "        if self.mode==\"pretrain\":\n",
    "            return super().metrics + [self.mae_metric]\n",
    "        else:\n",
    "            return [self.train_acc, self.val_acc]\n",
    "    \n",
    "    def make_representation(self, val_data, val_label, device='gpu'):\n",
    "        out = []\n",
    "        labels = []\n",
    "        for x, targets in zip(val_data,val_label): #shape of x (64,2500)\n",
    "            x = tf.convert_to_tensor(x)\n",
    "            x = tf.expand_dims(x, axis=0)\n",
    "\n",
    "            with tf.device(device):\n",
    "                rep = self.linear_prob(x, training=False)\n",
    "\n",
    "            out.append(rep.numpy())\n",
    "            labels.append(targets)\n",
    "\n",
    "        out = np.array(out)\n",
    "        labels = np.array(labels)\n",
    "        return out, labels\n",
    "    \n",
    "    def test_step(self, data):\n",
    "\n",
    "        x, y = data\n",
    "        predictions = self.downstream(x, training=False)\n",
    "        loss = self.compiled_loss(y, predictions)\n",
    "        acc = masked_accuracy(y, predictions)\n",
    "        with self.summary_writer.as_default():\n",
    "            step = tf.cast(self.optimizer.iterations, tf.int64)\n",
    "            tf.summary.scalar('val_accuracy', acc, step=step)\n",
    "        self.val_acc.update_state(acc)\n",
    "        return {\"loss\": loss, \"accuracy\": self.val_acc.result()}\n",
    "\n",
    "    def train_step(self, data):\n",
    "        if self.mode==\"pretrain\":\n",
    "            # Unpack the data\n",
    "            x = data\n",
    "\n",
    "            # Ensure the copy_weight function is called only at the start of training\n",
    "            if not hasattr(self, \"_weights_copied\") or not self._weights_copied:\n",
    "                self.copy_weight()  # Call the copy_weight function\n",
    "                self._weights_copied = True\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Forward pass\n",
    "                rep_mask, rep_mask_prediction, _, _ = self(x, training=True)\n",
    "\n",
    "                # Compute the reconstruction loss\n",
    "                reconstruction_loss = self.compute_loss(y=rep_mask, y_pred=rep_mask_prediction)\n",
    "\n",
    "                # Compute the variance and covariance regularization terms using VICReg\n",
    "                representations = tf.transpose(rep_mask_prediction, perm=[0, 2, 1])\n",
    "                y = tf.reduce_mean(representations, axis=2)\n",
    "                y = y - tf.reduce_mean(y, axis=0, keepdims=True)\n",
    "\n",
    "                std_y = tf.sqrt(tf.math.reduce_variance(y, axis=0) + 0.0001)\n",
    "                variance_loss = tf.reduce_mean(tf.nn.relu(1 - std_y))  # Hinge loss\n",
    "\n",
    "                cov_matrix = tf.matmul(y, y, transpose_a=True) / tf.cast(tf.shape(y)[0] - 1, tf.float32)\n",
    "                cov_matrix = cov_matrix - tf.linalg.diag(tf.linalg.diag_part(cov_matrix))\n",
    "                covariance_loss = tf.reduce_sum(tf.square(cov_matrix)) / tf.cast(tf.shape(y)[-1], tf.float32)\n",
    "\n",
    "                # Total loss\n",
    "                total_loss = (\n",
    "                    self.lambda_ * reconstruction_loss\n",
    "                    + self.mu * variance_loss\n",
    "                    + self.gamma * covariance_loss\n",
    "                )\n",
    "\n",
    "            # Compute gradients\n",
    "            trainable_vars = self.trainable_variables\n",
    "            gradients = tape.gradient(total_loss, trainable_vars)\n",
    "\n",
    "            # Update weights\n",
    "            self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "            # Update built-in metrics\n",
    "            self.mae_metric.update_state(rep_mask, rep_mask_prediction)\n",
    "\n",
    "            # Calculate and log custom metrics\n",
    "            dtw_value = self.dtw(rep_mask, rep_mask_prediction)\n",
    "            pcc_value = self.pcc_met(rep_mask, rep_mask_prediction)\n",
    "            cosine_similarity_value = self.cosine_sim(rep_mask, rep_mask_prediction)\n",
    "\n",
    "            with self.summary_writer.as_default():\n",
    "                tf.summary.scalar('loss', total_loss, step=self.optimizer.iterations)\n",
    "                tf.summary.scalar('mae', self.mae_metric.result(), step=self.optimizer.iterations)\n",
    "    #             tf.summary.scalar('dtw', dtw_value, step=self.optimizer.iterations)\n",
    "                tf.summary.scalar('PCC', pcc_value, step=self.optimizer.iterations)\n",
    "                tf.summary.scalar('Cosine Similarity', cosine_similarity_value, step=self.optimizer.iterations)\n",
    "\n",
    "            self.momentum_update()\n",
    "\n",
    "            # Return a dictionary of metric results\n",
    "            return {\n",
    "                \"loss\": total_loss,\n",
    "                \"mae\": self.mae_metric.result(),\n",
    "                \"dtw\": dtw_value,\n",
    "                \"pcc\": pcc_value,\n",
    "                \"cosine_sim\": cosine_similarity_value,\n",
    "            }\n",
    "\n",
    "        else:\n",
    "            # Downstream mode using BERT.\n",
    "            x, y = data[0], data[1]\n",
    "            with tf.GradientTape() as tape:\n",
    "                predictions = self.downstream(x, training=True)\n",
    "                loss = self.compiled_loss(y, predictions)\n",
    "                acc = masked_accuracy(y, predictions)\n",
    "                \n",
    "            gradients = tape.gradient(loss, self.trainable_variables)\n",
    "            self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "            \n",
    "            with self.summary_writer.as_default():\n",
    "                step = tf.cast(self.optimizer.iterations, tf.int64)\n",
    "                tf.summary.scalar('downstream_loss', loss, step=step)\n",
    "                tf.summary.scalar('train_mask_acc', acc, step=step)\n",
    "#                 results = {m.name: m.result() for m in self.metrics}\n",
    "#                 results.update({\"loss\": loss})\n",
    "            self.train_acc.update_state(acc)\n",
    "            return {\"loss\": loss, \"accuracy\": self.train_acc.result()}\n",
    "    \n",
    "\n",
    "\n",
    "    def copy_weight(self):\n",
    "        for target_var, context_var in zip(self.target_encoder.trainable_variables, self.contex_encoder.trainable_variables):\n",
    "            target_var.assign(context_var)\n",
    "\n",
    "    def momentum_update(self):\n",
    "        for target_var, context_var in zip(self.target_encoder.trainable_variables, self.contex_encoder.trainable_variables):\n",
    "            target_var.assign(self.momentum * target_var + (1 - self.momentum) * context_var)\n",
    "\n",
    "    def linear_prob(self, x, training=False): #Used for evaluation of learnt embeddings frozen weights\n",
    "        patches = tf.stop_gradient(self.ViT(x))\n",
    "        patches = tf.stop_gradient(self.Norm(patches))\n",
    "        patches = tf.stop_gradient(patches + self.PositionalEncoding(patches))\n",
    "        patches = tf.stop_gradient(self.Norm2(patches))\n",
    "        out = tf.stop_gradient(self.contex_encoder(patches,training=training))\n",
    "        out = tf.transpose(out, perm=[0, 2, 1])\n",
    "        out = self.gap(out)\n",
    "        return tf.squeeze(out)\n",
    "\n",
    "    def pretrain_forward(self, x, training=True):\n",
    "        patches = self.ViT(x)  # (Batch, l//m, d_x)\n",
    "        patches = self.Norm(patches)\n",
    "        patches = patches + self.PositionalEncoding(patches)\n",
    "        patches = self.Norm2(patches) # (Batch, l//m, d_x) = (64, 512, 256)\n",
    "\n",
    "        batch_size = tf.shape(patches)[0] #64\n",
    "        seq_len = tf.shape(patches)[1] #512\n",
    "        rep_mask_token = tf.tile(self.mask_token[tf.newaxis, tf.newaxis, :], [batch_size, seq_len, 1])\n",
    "        rep_mask_token = rep_mask_token + self.PositionalEncoding(rep_mask_token)\n",
    "        index = np.arange(patches.shape[1])\n",
    "        index_chunk = Semantic_Subsequence_Preserving(index, 2, self.mask_ratio)\n",
    "        v_index = np.ravel(index_chunk)\n",
    "        m_index = np.setdiff1d(index, v_index)\n",
    "        \n",
    "        # visible = patches[:, v_index, :]\n",
    "# Ensure v_index is a TensorFlow tensor of integer type\n",
    "        v_index = tf.constant(v_index, dtype=tf.int32)\n",
    "\n",
    "        # Use tf.gather to index along the second dimension\n",
    "        visible = tf.gather(patches, v_index, axis=1)\n",
    "        m_index = tf.constant(m_index, dtype=tf.int32)\n",
    "        rep_mask_token = tf.gather(rep_mask_token, m_index, axis=1)\n",
    "        rep_contex = self.contex_encoder(visible, training=training)\n",
    "\n",
    "        rep_target = tf.stop_gradient(self.target_encoder(patches, training=training))\n",
    "        rep_mask = tf.gather(rep_target, m_index, axis=1)\n",
    "        rep_mask_prediction = self.Predictor(rep_contex, rep_mask_token, training=training)\n",
    "        return [rep_mask, rep_mask_prediction, rep_contex, rep_target]\n",
    "\n",
    "    def downstream(self, x, training=True):\n",
    "        patches = self.ViT(x)\n",
    "        patches = self.Norm(patches)\n",
    "        patches = patches + self.PositionalEncoding(patches)\n",
    "        patches = self.Norm2(patches)\n",
    "        rep = self.contex_encoder(patches, training=training)\n",
    "\n",
    "        # Ensure rep has a well-defined shape\n",
    "        rep_shape = tf.shape(rep)\n",
    "        batch_size = rep_shape[0]\n",
    "        feature_size = rep_shape[1] * rep_shape[2]  # Flatten the last two dimensions\n",
    "        rep = tf.reshape(rep, [batch_size, feature_size])\n",
    "\n",
    "        # Apply projection to match BERT's expected input dimension\n",
    "        projected = self.downstream_projection(rep)\n",
    "        bert_logits = self.bert(projected, training=training)\n",
    "        return bert_logits\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        if training:\n",
    "            if self.mode == \"pretrain\":\n",
    "                return self.pretrain_forward(x, training=training)\n",
    "            else:\n",
    "                return self.downstream(x, training=training)\n",
    "        else:\n",
    "            return self.linear_prob(x, training=training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e581e10",
   "metadata": {
    "id": "2xvQ_UIyqy2m"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/swin/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.bert.modeling_tf_bert because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/workspace/swin/lib/python3.10/site-packages/transformers/activations_tf.py:22\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tf_keras'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/workspace/swin/lib/python3.10/site-packages/transformers/utils/import_utils.py:1976\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1975\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1976\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1977\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m/workspace/swin/lib/python3.10/site-packages/transformers/models/bert/modeling_tf_bert.py:28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations_tf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_tf_activation\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_tf_outputs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     30\u001b[0m     TFBaseModelOutputWithPastAndCrossAttentions,\n\u001b[1;32m     31\u001b[0m     TFBaseModelOutputWithPoolingAndCrossAttentions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m     TFTokenClassifierOutput,\n\u001b[1;32m     39\u001b[0m )\n",
      "File \u001b[0;32m/workspace/swin/lib/python3.10/site-packages/transformers/activations_tf.py:27\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parse(keras\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mmajor \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     28\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour currently installed version of Keras is Keras 3, but this is not yet supported in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformers. Please install the backwards-compatible tf-keras package with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install tf-keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m         )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gelu\u001b[39m(x):\n",
      "\u001b[0;31mValueError\u001b[0m: Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m  \u001b[38;5;66;03m# Example number of output classes\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Initialize the model\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mEEG2Rep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Training callbacks\u001b[39;00m\n\u001b[1;32m     35\u001b[0m callbacks_pre \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     36\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mViT_bert_emb1024_pre.keras\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     37\u001b[0m ]\n",
      "Cell \u001b[0;32mIn[20], line 38\u001b[0m, in \u001b[0;36mEEG2Rep.__init__\u001b[0;34m(self, config, num_classes)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpcc_met \u001b[38;5;241m=\u001b[39m pcc_metric\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcosine_sim \u001b[38;5;241m=\u001b[39m cosine_similarity_metric\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_eeg_to_text_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Create a projection layer to map our EEG representation to the input shape expected by BERT.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# (The BERT branch expects inputs of shape (1375,), so we project to that dimension.)\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownstream_projection \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m1375\u001b[39m)\n",
      "Cell \u001b[0;32mIn[19], line 42\u001b[0m, in \u001b[0;36mbuild_eeg_to_text_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m x \u001b[38;5;241m=\u001b[39m Reshape((max_seq_len, \u001b[38;5;241m768\u001b[39m))(x)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Load BERT with correct expectations\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m bert \u001b[38;5;241m=\u001b[39m \u001b[43mTFAutoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_loading_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Suppress warnings\u001b[39;49;00m\n\u001b[1;32m     45\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# Sometimes helps with compatibility\u001b[39;49;00m\n\u001b[1;32m     46\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Get encoder outputs\u001b[39;00m\n\u001b[1;32m     49\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m bert(input_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, inputs_embeds\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mcast(x, tf\u001b[38;5;241m.\u001b[39mfloat32), training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mlast_hidden_state\n",
      "File \u001b[0;32m/workspace/swin/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:572\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    569\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    570\u001b[0m     )\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m--> 572\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m \u001b[43m_get_model_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_mapping\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    574\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    575\u001b[0m     )\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m )\n",
      "File \u001b[0;32m/workspace/swin/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:388\u001b[0m, in \u001b[0;36m_get_model_class\u001b[0;34m(config, model_mapping)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_model_class\u001b[39m(config, model_mapping):\n\u001b[0;32m--> 388\u001b[0m     supported_models \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(supported_models, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    390\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m supported_models\n",
      "File \u001b[0;32m/workspace/swin/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:772\u001b[0m, in \u001b[0;36m_LazyAutoMapping.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_type \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping:\n\u001b[1;32m    771\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping[model_type]\n\u001b[0;32m--> 772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_attr_from_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[38;5;66;03m# Maybe there was several model types associated with this config.\u001b[39;00m\n\u001b[1;32m    775\u001b[0m model_types \u001b[38;5;241m=\u001b[39m [k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config_mapping\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;241m==\u001b[39m key\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m]\n",
      "File \u001b[0;32m/workspace/swin/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:786\u001b[0m, in \u001b[0;36m_LazyAutoMapping._load_attr_from_module\u001b[0;34m(self, model_type, attr)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules[module_name] \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformers.models\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 786\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgetattribute_from_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_modules\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/swin/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:702\u001b[0m, in \u001b[0;36mgetattribute_from_module\u001b[0;34m(module, attr)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(attr, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(getattribute_from_module(module, a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m attr)\n\u001b[0;32m--> 702\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, attr)\n\u001b[1;32m    704\u001b[0m \u001b[38;5;66;03m# Some of the mappings have entries model_type -> object of another model type. In that case we try to grab the\u001b[39;00m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# object at the top level.\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/swin/lib/python3.10/site-packages/transformers/utils/import_utils.py:1964\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1962\u001b[0m     value \u001b[38;5;241m=\u001b[39m Placeholder\n\u001b[1;32m   1963\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1964\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1965\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1966\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n",
      "File \u001b[0;32m/workspace/swin/lib/python3.10/site-packages/transformers/utils/import_utils.py:1978\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1976\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1977\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1978\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1979\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1980\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1981\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.models.bert.modeling_tf_bert because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`."
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the configuration\n",
    "config={\n",
    "    'Data_shape': (59360, 64, 2750),\n",
    "    'dropout': 0.1,\n",
    "    'Norm': False,\n",
    "    'val_interval': 2,\n",
    "    'key_metric': 'loss',\n",
    "    'Training_mode': 'Rep-Learning',\n",
    "    'Pre_Training': 'In-domain',\n",
    "    'Input_Embedding': ['C'],\n",
    "    'Pos_Embedding': ['Sin'],\n",
    "    'Encoder': ['T'],\n",
    "    'layers': 4,\n",
    "    'pre_layers': 2,\n",
    "    'mask_ratio': 0.5,\n",
    "    'momentum': 0.99,\n",
    "    'patch_size': 8,\n",
    "    'emb_size': 1024,\n",
    "    'dim_ff': 256,\n",
    "    'num_heads': 8,\n",
    "    'device': 'cuda',\n",
    "    'num_labels' : 10,\n",
    "    'lambda': 1.0,\n",
    "    'mu': 0.1,\n",
    "    'gamma': 0.005,\n",
    "    'pooling_size': 2\n",
    "}\n",
    "\n",
    "\n",
    "num_classes = 30  # Example number of output classes\n",
    "\n",
    "# Initialize the model\n",
    "model = EEG2Rep(config, num_classes)\n",
    "# Training callbacks\n",
    "callbacks_pre = [\n",
    "    tf.keras.callbacks.ModelCheckpoint('ViT_bert_emb1024_pre.keras', save_best_only=True, save_weights_only=True)\n",
    "]\n",
    "# Run the forward pass for classification\n",
    "model.compile(optimizer='AdamW', loss='MSE')\n",
    "model.mode = \"pretrain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8df450",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[:,:64,:]\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab3bedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['eeg2_rep/encoder/transformer_block/sublayer_connection/multi_head_attention_2/dense_7/kernel:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection/multi_head_attention_2/dense_7/bias:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection/multi_head_attention_2/dense_8/kernel:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection/multi_head_attention_2/dense_8/bias:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection/multi_head_attention_2/dense_9/kernel:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection/multi_head_attention_2/dense_9/bias:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection/multi_head_attention_2/dense_10/kernel:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection/multi_head_attention_2/dense_10/bias:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection_1/point_wise_feed_forward/dense_11/kernel:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection_1/point_wise_feed_forward/dense_11/bias:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection_1/point_wise_feed_forward/dense_12/kernel:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection_1/point_wise_feed_forward/dense_12/bias:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection/layer_normalization_5/gamma:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection/layer_normalization_5/beta:0', 'Variable:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection_1/layer_normalization_6/gamma:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection_1/layer_normalization_6/beta:0', 'Variable:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/multi_head_attention_3/dense_13/kernel:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/multi_head_attention_3/dense_13/bias:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/multi_head_attention_3/dense_14/kernel:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/multi_head_attention_3/dense_14/bias:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/multi_head_attention_3/dense_15/kernel:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/multi_head_attention_3/dense_15/bias:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/multi_head_attention_3/dense_16/kernel:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/multi_head_attention_3/dense_16/bias:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_3/point_wise_feed_forward_1/dense_17/kernel:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_3/point_wise_feed_forward_1/dense_17/bias:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_3/point_wise_feed_forward_1/dense_18/kernel:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_3/point_wise_feed_forward_1/dense_18/bias:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/layer_normalization_7/gamma:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/layer_normalization_7/beta:0', 'Variable:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_3/layer_normalization_8/gamma:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_3/layer_normalization_8/beta:0', 'Variable:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/multi_head_attention_4/dense_19/kernel:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/multi_head_attention_4/dense_19/bias:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/multi_head_attention_4/dense_20/kernel:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/multi_head_attention_4/dense_20/bias:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/multi_head_attention_4/dense_21/kernel:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/multi_head_attention_4/dense_21/bias:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/multi_head_attention_4/dense_22/kernel:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/multi_head_attention_4/dense_22/bias:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_5/point_wise_feed_forward_2/dense_23/kernel:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_5/point_wise_feed_forward_2/dense_23/bias:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_5/point_wise_feed_forward_2/dense_24/kernel:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_5/point_wise_feed_forward_2/dense_24/bias:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/layer_normalization_9/gamma:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/layer_normalization_9/beta:0', 'Variable:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_5/layer_normalization_10/gamma:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_5/layer_normalization_10/beta:0', 'Variable:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/multi_head_attention_5/dense_25/kernel:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/multi_head_attention_5/dense_25/bias:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/multi_head_attention_5/dense_26/kernel:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/multi_head_attention_5/dense_26/bias:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/multi_head_attention_5/dense_27/kernel:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/multi_head_attention_5/dense_27/bias:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/multi_head_attention_5/dense_28/kernel:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/multi_head_attention_5/dense_28/bias:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_7/point_wise_feed_forward_3/dense_29/kernel:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_7/point_wise_feed_forward_3/dense_29/bias:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_7/point_wise_feed_forward_3/dense_30/kernel:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_7/point_wise_feed_forward_3/dense_30/bias:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/layer_normalization_11/gamma:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/layer_normalization_11/beta:0', 'Variable:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_7/layer_normalization_12/gamma:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_7/layer_normalization_12/beta:0', 'Variable:0', 'layer_normalization_19/gamma:0', 'layer_normalization_19/beta:0', 'dense_44/kernel:0', 'dense_44/bias:0', 'tf_bert_model/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._11/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._11/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._11/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._11/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._11/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/beta:0', 'tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0', 'dense_45/kernel:0', 'dense_45/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['eeg2_rep/encoder/transformer_block/sublayer_connection/multi_head_attention_2/dense_7/kernel:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection/multi_head_attention_2/dense_7/bias:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection/multi_head_attention_2/dense_8/kernel:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection/multi_head_attention_2/dense_8/bias:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection/multi_head_attention_2/dense_9/kernel:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection/multi_head_attention_2/dense_9/bias:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection/multi_head_attention_2/dense_10/kernel:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection/multi_head_attention_2/dense_10/bias:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection_1/point_wise_feed_forward/dense_11/kernel:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection_1/point_wise_feed_forward/dense_11/bias:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection_1/point_wise_feed_forward/dense_12/kernel:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection_1/point_wise_feed_forward/dense_12/bias:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection/layer_normalization_5/gamma:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection/layer_normalization_5/beta:0', 'Variable:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection_1/layer_normalization_6/gamma:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection_1/layer_normalization_6/beta:0', 'Variable:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/multi_head_attention_3/dense_13/kernel:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/multi_head_attention_3/dense_13/bias:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/multi_head_attention_3/dense_14/kernel:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/multi_head_attention_3/dense_14/bias:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/multi_head_attention_3/dense_15/kernel:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/multi_head_attention_3/dense_15/bias:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/multi_head_attention_3/dense_16/kernel:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/multi_head_attention_3/dense_16/bias:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_3/point_wise_feed_forward_1/dense_17/kernel:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_3/point_wise_feed_forward_1/dense_17/bias:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_3/point_wise_feed_forward_1/dense_18/kernel:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_3/point_wise_feed_forward_1/dense_18/bias:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/layer_normalization_7/gamma:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/layer_normalization_7/beta:0', 'Variable:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_3/layer_normalization_8/gamma:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_3/layer_normalization_8/beta:0', 'Variable:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/multi_head_attention_4/dense_19/kernel:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/multi_head_attention_4/dense_19/bias:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/multi_head_attention_4/dense_20/kernel:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/multi_head_attention_4/dense_20/bias:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/multi_head_attention_4/dense_21/kernel:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/multi_head_attention_4/dense_21/bias:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/multi_head_attention_4/dense_22/kernel:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/multi_head_attention_4/dense_22/bias:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_5/point_wise_feed_forward_2/dense_23/kernel:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_5/point_wise_feed_forward_2/dense_23/bias:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_5/point_wise_feed_forward_2/dense_24/kernel:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_5/point_wise_feed_forward_2/dense_24/bias:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/layer_normalization_9/gamma:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/layer_normalization_9/beta:0', 'Variable:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_5/layer_normalization_10/gamma:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_5/layer_normalization_10/beta:0', 'Variable:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/multi_head_attention_5/dense_25/kernel:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/multi_head_attention_5/dense_25/bias:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/multi_head_attention_5/dense_26/kernel:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/multi_head_attention_5/dense_26/bias:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/multi_head_attention_5/dense_27/kernel:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/multi_head_attention_5/dense_27/bias:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/multi_head_attention_5/dense_28/kernel:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/multi_head_attention_5/dense_28/bias:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_7/point_wise_feed_forward_3/dense_29/kernel:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_7/point_wise_feed_forward_3/dense_29/bias:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_7/point_wise_feed_forward_3/dense_30/kernel:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_7/point_wise_feed_forward_3/dense_30/bias:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/layer_normalization_11/gamma:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/layer_normalization_11/beta:0', 'Variable:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_7/layer_normalization_12/gamma:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_7/layer_normalization_12/beta:0', 'Variable:0', 'layer_normalization_19/gamma:0', 'layer_normalization_19/beta:0', 'dense_44/kernel:0', 'dense_44/bias:0', 'tf_bert_model/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._11/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._11/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._11/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._11/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._11/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/beta:0', 'tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0', 'dense_45/kernel:0', 'dense_45/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['eeg2_rep/encoder/transformer_block/sublayer_connection/multi_head_attention_2/dense_7/kernel:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection/multi_head_attention_2/dense_7/bias:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection/multi_head_attention_2/dense_8/kernel:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection/multi_head_attention_2/dense_8/bias:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection/multi_head_attention_2/dense_9/kernel:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection/multi_head_attention_2/dense_9/bias:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection/multi_head_attention_2/dense_10/kernel:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection/multi_head_attention_2/dense_10/bias:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection_1/point_wise_feed_forward/dense_11/kernel:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection_1/point_wise_feed_forward/dense_11/bias:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection_1/point_wise_feed_forward/dense_12/kernel:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection_1/point_wise_feed_forward/dense_12/bias:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection/layer_normalization_5/gamma:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection/layer_normalization_5/beta:0', 'Variable:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection_1/layer_normalization_6/gamma:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection_1/layer_normalization_6/beta:0', 'Variable:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/multi_head_attention_3/dense_13/kernel:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/multi_head_attention_3/dense_13/bias:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/multi_head_attention_3/dense_14/kernel:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/multi_head_attention_3/dense_14/bias:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/multi_head_attention_3/dense_15/kernel:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/multi_head_attention_3/dense_15/bias:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/multi_head_attention_3/dense_16/kernel:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/multi_head_attention_3/dense_16/bias:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_3/point_wise_feed_forward_1/dense_17/kernel:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_3/point_wise_feed_forward_1/dense_17/bias:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_3/point_wise_feed_forward_1/dense_18/kernel:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_3/point_wise_feed_forward_1/dense_18/bias:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/layer_normalization_7/gamma:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/layer_normalization_7/beta:0', 'Variable:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_3/layer_normalization_8/gamma:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_3/layer_normalization_8/beta:0', 'Variable:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/multi_head_attention_4/dense_19/kernel:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/multi_head_attention_4/dense_19/bias:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/multi_head_attention_4/dense_20/kernel:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/multi_head_attention_4/dense_20/bias:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/multi_head_attention_4/dense_21/kernel:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/multi_head_attention_4/dense_21/bias:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/multi_head_attention_4/dense_22/kernel:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/multi_head_attention_4/dense_22/bias:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_5/point_wise_feed_forward_2/dense_23/kernel:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_5/point_wise_feed_forward_2/dense_23/bias:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_5/point_wise_feed_forward_2/dense_24/kernel:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_5/point_wise_feed_forward_2/dense_24/bias:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/layer_normalization_9/gamma:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/layer_normalization_9/beta:0', 'Variable:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_5/layer_normalization_10/gamma:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_5/layer_normalization_10/beta:0', 'Variable:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/multi_head_attention_5/dense_25/kernel:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/multi_head_attention_5/dense_25/bias:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/multi_head_attention_5/dense_26/kernel:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/multi_head_attention_5/dense_26/bias:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/multi_head_attention_5/dense_27/kernel:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/multi_head_attention_5/dense_27/bias:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/multi_head_attention_5/dense_28/kernel:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/multi_head_attention_5/dense_28/bias:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_7/point_wise_feed_forward_3/dense_29/kernel:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_7/point_wise_feed_forward_3/dense_29/bias:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_7/point_wise_feed_forward_3/dense_30/kernel:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_7/point_wise_feed_forward_3/dense_30/bias:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/layer_normalization_11/gamma:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/layer_normalization_11/beta:0', 'Variable:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_7/layer_normalization_12/gamma:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_7/layer_normalization_12/beta:0', 'Variable:0', 'layer_normalization_19/gamma:0', 'layer_normalization_19/beta:0', 'dense_44/kernel:0', 'dense_44/bias:0', 'tf_bert_model/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._11/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._11/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._11/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._11/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._11/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/beta:0', 'tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0', 'dense_45/kernel:0', 'dense_45/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['eeg2_rep/encoder/transformer_block/sublayer_connection/multi_head_attention_2/dense_7/kernel:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection/multi_head_attention_2/dense_7/bias:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection/multi_head_attention_2/dense_8/kernel:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection/multi_head_attention_2/dense_8/bias:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection/multi_head_attention_2/dense_9/kernel:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection/multi_head_attention_2/dense_9/bias:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection/multi_head_attention_2/dense_10/kernel:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection/multi_head_attention_2/dense_10/bias:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection_1/point_wise_feed_forward/dense_11/kernel:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection_1/point_wise_feed_forward/dense_11/bias:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection_1/point_wise_feed_forward/dense_12/kernel:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection_1/point_wise_feed_forward/dense_12/bias:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection/layer_normalization_5/gamma:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection/layer_normalization_5/beta:0', 'Variable:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection_1/layer_normalization_6/gamma:0', 'eeg2_rep/encoder/transformer_block/sublayer_connection_1/layer_normalization_6/beta:0', 'Variable:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/multi_head_attention_3/dense_13/kernel:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/multi_head_attention_3/dense_13/bias:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/multi_head_attention_3/dense_14/kernel:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/multi_head_attention_3/dense_14/bias:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/multi_head_attention_3/dense_15/kernel:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/multi_head_attention_3/dense_15/bias:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/multi_head_attention_3/dense_16/kernel:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/multi_head_attention_3/dense_16/bias:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_3/point_wise_feed_forward_1/dense_17/kernel:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_3/point_wise_feed_forward_1/dense_17/bias:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_3/point_wise_feed_forward_1/dense_18/kernel:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_3/point_wise_feed_forward_1/dense_18/bias:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/layer_normalization_7/gamma:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_2/layer_normalization_7/beta:0', 'Variable:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_3/layer_normalization_8/gamma:0', 'eeg2_rep/encoder/transformer_block_1/sublayer_connection_3/layer_normalization_8/beta:0', 'Variable:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/multi_head_attention_4/dense_19/kernel:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/multi_head_attention_4/dense_19/bias:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/multi_head_attention_4/dense_20/kernel:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/multi_head_attention_4/dense_20/bias:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/multi_head_attention_4/dense_21/kernel:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/multi_head_attention_4/dense_21/bias:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/multi_head_attention_4/dense_22/kernel:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/multi_head_attention_4/dense_22/bias:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_5/point_wise_feed_forward_2/dense_23/kernel:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_5/point_wise_feed_forward_2/dense_23/bias:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_5/point_wise_feed_forward_2/dense_24/kernel:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_5/point_wise_feed_forward_2/dense_24/bias:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/layer_normalization_9/gamma:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_4/layer_normalization_9/beta:0', 'Variable:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_5/layer_normalization_10/gamma:0', 'eeg2_rep/encoder/transformer_block_2/sublayer_connection_5/layer_normalization_10/beta:0', 'Variable:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/multi_head_attention_5/dense_25/kernel:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/multi_head_attention_5/dense_25/bias:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/multi_head_attention_5/dense_26/kernel:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/multi_head_attention_5/dense_26/bias:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/multi_head_attention_5/dense_27/kernel:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/multi_head_attention_5/dense_27/bias:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/multi_head_attention_5/dense_28/kernel:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/multi_head_attention_5/dense_28/bias:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_7/point_wise_feed_forward_3/dense_29/kernel:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_7/point_wise_feed_forward_3/dense_29/bias:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_7/point_wise_feed_forward_3/dense_30/kernel:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_7/point_wise_feed_forward_3/dense_30/bias:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/layer_normalization_11/gamma:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_6/layer_normalization_11/beta:0', 'Variable:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_7/layer_normalization_12/gamma:0', 'eeg2_rep/encoder/transformer_block_3/sublayer_connection_7/layer_normalization_12/beta:0', 'Variable:0', 'layer_normalization_19/gamma:0', 'layer_normalization_19/beta:0', 'dense_44/kernel:0', 'dense_44/bias:0', 'tf_bert_model/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._11/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._11/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._11/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._11/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._11/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/beta:0', 'tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0', 'dense_45/kernel:0', 'dense_45/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1739686541.435310  166078 service.cc:145] XLA service 0x7fecf806bf10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1739686541.435335  166078 service.cc:153]   StreamExecutor device (0): NVIDIA H100 80GB HBM3, Compute Capability 9.0\n",
      "I0000 00:00:1739686541.532100  166078 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502/502 [==============================] - ETA: 0s - loss: 0.5475 - mae: 0.4465 - dtw: 41230.2408 - pcc: 0.7554 - cosine_sim: 0.7554WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "502/502 [==============================] - 511s 902ms/step - loss: 0.5475 - mae: 0.4463 - dtw: 41182.8871 - pcc: 0.7554 - cosine_sim: 0.7553\n",
      "Epoch 2/100\n",
      "502/502 [==============================] - ETA: 0s - loss: 0.6528 - mae: 0.2661 - dtw: 135605.3739 - pcc: 0.7292 - cosine_sim: 0.7280WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "502/502 [==============================] - 447s 891ms/step - loss: 0.6528 - mae: 0.2661 - dtw: 135422.1683 - pcc: 0.7291 - cosine_sim: 0.7279\n",
      "Epoch 3/100\n",
      "200/502 [==========>...................] - ETA: 4:24 - loss: 0.6653 - mae: 0.2246 - dtw: 175966.6630 - pcc: 0.7057 - cosine_sim: 0.7026"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, batch_size=16, epochs=100, callbacks=callbacks_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb682ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = np.load(\"stacked_val.npy\")\n",
    "val_labels = make_label(val_data)\n",
    "val_data = val_data[:,:64,:]\n",
    "val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aa0a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_sentences = [sentence_dict[sid] for sid in val_labels]\n",
    "\n",
    "tokenized1 = tokenizer(y_sentences, padding='max_length', truncation=True, return_tensors=\"tf\")\n",
    "\n",
    "y_val_input_ids = tf.convert_to_tensor(tokenized1[\"input_ids\"], dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9dfbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting Downstream Fine-Tuning...\")\n",
    "model.mode = \"downstream\"  # Switch mode to downstream.\n",
    "# For downstream, compile with the BERT masked loss and appropriate metrics.\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Split data (assuming X_eeg and y_input_ids are your features and labels)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#     train_data, \n",
    "#     y_input_ids.numpy(),\n",
    "#     test_size=0.2,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "\n",
    "# Convert back to tensors\n",
    "X_train = tf.convert_to_tensor(train_data)\n",
    "X_val = tf.convert_to_tensor(val_data)\n",
    "y_train = y_input_ids\n",
    "y_val = y_val_input_ids\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=masked_loss,\n",
    "    metrics=[masked_accuracy]\n",
    ")\n",
    "history1 = model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21ef2e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"saved_models/ViT_emb1024_pre/ViT_emb1024_pre.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a99122d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_from_eeg(eeg_embedding, model, tokenizer, max_length=30):\n",
    "    # Convert input to tensor and add batch dimension\n",
    "    eeg_input = tf.convert_to_tensor(eeg_embedding, dtype=tf.float32)\n",
    "    if len(eeg_input.shape) == 1:\n",
    "        eeg_input = tf.expand_dims(eeg_input, axis=0)  # Shape: [1, 1375]\n",
    "\n",
    "    # Initialize sequence with proper dimensions\n",
    "    generated_ids = tf.constant([[tokenizer.cls_token_id]], dtype=tf.int32)  # Shape: [1, 1]\n",
    "    \n",
    "    for _ in range(max_length):\n",
    "        # Get predictions for all positions\n",
    "        logits = model(eeg_input)  # Shape: [1, seq_len, vocab_size]\n",
    "        \n",
    "        # Get the position we need to predict next (current sequence length)\n",
    "        pos = generated_ids.shape[-1] - 1\n",
    "        \n",
    "        # Focus on the relevant position's logits\n",
    "        next_token_logits = logits[:, pos, :]  # Shape: [1, vocab_size]\n",
    "        \n",
    "        # Greedy decoding\n",
    "        next_token = tf.argmax(next_token_logits, axis=-1, output_type=tf.int32)  # Shape: [1]\n",
    "        \n",
    "        # Reshape for proper concatenation\n",
    "        next_token = tf.reshape(next_token, (1, 1))  # Shape: [1, 1]\n",
    "        \n",
    "        # Stop if [SEP] token is generated\n",
    "        if next_token.numpy()[0][0] == tokenizer.sep_token_id:\n",
    "            break\n",
    "            \n",
    "        # Concatenate with proper dimensions\n",
    "        generated_ids = tf.concat([generated_ids, next_token], axis=-1)\n",
    "\n",
    "        # Early exit if sequence reaches max length\n",
    "        if generated_ids.shape[-1] >= max_length:\n",
    "            break\n",
    "\n",
    "    # Convert to text and remove special tokens\n",
    "    decoded = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8914e93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1375,)\n",
      "Generation failed: Exception encountered when calling layer 'sequential' (type Sequential).\n",
      "\n",
      "Input 0 of layer \"conv2d\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (1, 1, 1375)\n",
      "\n",
      "Call arguments received by layer 'sequential' (type Sequential):\n",
      "   inputs=tf.Tensor(shape=(1, 1, 1375), dtype=float32)\n",
      "   training=False\n",
      "   mask=None\n"
     ]
    }
   ],
   "source": [
    "# Verify preprocessing\n",
    "val_repr = np.load('train_repr_VIT.npy')\n",
    "X_eeg = tf.convert_to_tensor(val_repr, dtype=tf.float32)\n",
    "sample_eeg = X_eeg[200]  # Should be shape (1375,)\n",
    "print(\"Input shape:\", sample_eeg.shape)\n",
    "\n",
    "# Generate text\n",
    "try:\n",
    "    generated = generate_from_eeg(sample_eeg, model, tokenizer)\n",
    "    print(\"Generated:\", generated)\n",
    "    print(\"Original:\", sentence_dict[val_repr_labels[200]])  # Use same index\n",
    "except Exception as e:\n",
    "    print(\"Generation failed:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46edd9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1024, 64, 2750])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train[:1024].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4c925bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPUs will likely run quickly with dtype policy mixed_float16 as they all have compute capability of at least 7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing TFBertModel: ['mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFBertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert/pooler/dense/kernel:0', 'bert/pooler/dense/bias:0']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from transformers import AutoTokenizer, TFAutoModel\n",
    "# from tensorflow.keras.layers import Input, Dense, LayerNormalization, Reshape\n",
    "# from tensorflow.keras.models import Model\n",
    "\n",
    "# # Enable mixed precision training\n",
    "# tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# # Load and preprocess data\n",
    "# val_repr = np.load(\"train_repr_VIT.npy\")\n",
    "# val_repr_labels = np.load(\"train_repr_labels_VIT.npy\")\n",
    "# sentence_data = pd.read_csv('/workspace/Spanish.csv', encoding='latin-1')\n",
    "# sentence_dict = dict(zip(sentence_data['ID'], sentence_data['Sentence (Spanish)']))\n",
    "# y_sentences = [sentence_dict[sid] for sid in val_repr_labels]\n",
    "\n",
    "# # Tokenization setup with Spanish BERT\n",
    "# MODEL_NAME = \"dccuchile/bert-base-spanish-wwm-cased\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "# tokenized = tokenizer(y_sentences, padding='max_length', truncation=True, return_tensors=\"tf\")\n",
    "\n",
    "# # Convert to TensorFlow datasets\n",
    "# X_eeg = tf.convert_to_tensor(val_repr, dtype=tf.float32)\n",
    "# y_input_ids = tf.convert_to_tensor(tokenized[\"input_ids\"], dtype=tf.int32)\n",
    "# y_attention_mask = tf.convert_to_tensor(tokenized[\"attention_mask\"], dtype=tf.int32)\n",
    "\n",
    "# # Get sequence parameters\n",
    "# max_seq_len = y_input_ids.shape[1]\n",
    "# vocab_size = tokenizer.vocab_size\n",
    "\n",
    "# def build_eeg_to_text_model():\n",
    "#     eeg_input = Input(shape=(1375,), name=\"eeg_input\")\n",
    "    \n",
    "#     # Projection to BERT's space\n",
    "#     x = LayerNormalization()(eeg_input)\n",
    "#     x = Dense(768 * max_seq_len, activation='tanh')(x)\n",
    "#     x = Reshape((max_seq_len, 768))(x)\n",
    "    \n",
    "#     # Load BERT with correct expectations\n",
    "#     bert = TFAutoModel.from_pretrained(\n",
    "#         MODEL_NAME,\n",
    "#         output_loading_info=False  # Suppress warnings\n",
    "#           # Sometimes helps with compatibility\n",
    "#     )\n",
    "    \n",
    "#     # Get encoder outputs\n",
    "#     encoder_outputs = bert(input_ids = None, inputs_embeds=tf.cast(x, tf.float16), training=False).last_hidden_state\n",
    "    \n",
    "#     # Add task-specific head\n",
    "#     logits = Dense(vocab_size)(encoder_outputs)\n",
    "    \n",
    "#     return Model(inputs=eeg_input, outputs=logits)\n",
    "\n",
    "# # Masked loss function handling BERT's padding token (0)\n",
    "# def masked_loss(y_true, y_pred):\n",
    "#     loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)\n",
    "#     mask = tf.cast(y_true != tokenizer.pad_token_id, tf.float16)\n",
    "#     return tf.reduce_sum(loss * mask) / tf.reduce_sum(mask)\n",
    "\n",
    "# # Build and compile the model\n",
    "# model = build_eeg_to_text_model()\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5, clipnorm=1.0)\n",
    "# model.compile(optimizer=optimizer, loss=masked_loss, weighted_metrics=['accuracy'])\n",
    "\n",
    "# # Training callbacks\n",
    "# callbacks = [\n",
    "#     tf.keras.callbacks.TerminateOnNaN(),\n",
    "#     tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=2),\n",
    "#     tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "653db562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " eeg_input (InputLayer)      [(None, 1375)]            0         \n",
      "                                                                 \n",
      " layer_normalization (Layer  (None, 1375)              2750      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 393216)            541065216 \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 512, 768)          0         \n",
      "                                                                 \n",
      " tf.cast (TFOpLambda)        (None, 512, 768)          0         \n",
      "                                                                 \n",
      " tf_bert_model (TFBertModel  TFBaseModelOutputWithPo   109850880 \n",
      " )                           olingAndCrossAttentions             \n",
      "                             (last_hidden_state=(Non             \n",
      "                             e, 512, 768),                       \n",
      "                              pooler_output=(None, 7             \n",
      "                             68),                                \n",
      "                              past_key_values=None,              \n",
      "                             hidden_states=None, att             \n",
      "                             entions=None, cross_att             \n",
      "                             entions=None)                       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512, 31002)        23840538  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 674759384 (2.51 GB)\n",
      "Trainable params: 674759384 (2.51 GB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9fd0ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function create_autocast_variable at 0x7ffe1ff9dfc0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: <gast.gast.Expr object at 0x7ff8f06d2020>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function create_autocast_variable at 0x7ffe1ff9dfc0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: <gast.gast.Expr object at 0x7ff8f06d2020>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-04 18:55:21.448042: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 90100\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1738695323.406425 3125250 service.cc:145] XLA service 0x7fef5f8e9910 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1738695323.406457 3125250 service.cc:153]   StreamExecutor device (0): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "I0000 00:00:1738695323.406463 3125250 service.cc:153]   StreamExecutor device (1): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "I0000 00:00:1738695323.406467 3125250 service.cc:153]   StreamExecutor device (2): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "I0000 00:00:1738695323.406471 3125250 service.cc:153]   StreamExecutor device (3): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "I0000 00:00:1738695323.406474 3125250 service.cc:153]   StreamExecutor device (4): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "I0000 00:00:1738695323.406479 3125250 service.cc:153]   StreamExecutor device (5): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "I0000 00:00:1738695323.406484 3125250 service.cc:153]   StreamExecutor device (6): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "2025-02-04 18:55:23.412411: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1738695323.538348 3125250 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 182s 737ms/step - loss: 0.1554 - accuracy: 0.2279 - val_loss: 0.1430 - val_accuracy: 0.2491 - lr: 1.0000e-05\n",
      "Epoch 2/20\n",
      "143/143 [==============================] - 95s 662ms/step - loss: 0.1342 - accuracy: 0.2459 - val_loss: 0.1253 - val_accuracy: 0.2415 - lr: 1.0000e-05\n",
      "Epoch 3/20\n",
      "143/143 [==============================] - 95s 664ms/step - loss: 0.1161 - accuracy: 0.2348 - val_loss: 0.1068 - val_accuracy: 0.2303 - lr: 1.0000e-05\n",
      "Epoch 4/20\n",
      "143/143 [==============================] - 95s 666ms/step - loss: 0.0980 - accuracy: 0.2306 - val_loss: 0.0897 - val_accuracy: 0.2303 - lr: 1.0000e-05\n",
      "Epoch 5/20\n",
      "143/143 [==============================] - 96s 668ms/step - loss: 0.0830 - accuracy: 0.2353 - val_loss: 0.0770 - val_accuracy: 0.2491 - lr: 1.0000e-05\n",
      "Epoch 6/20\n",
      "143/143 [==============================] - 95s 667ms/step - loss: 0.0725 - accuracy: 0.2532 - val_loss: 0.0686 - val_accuracy: 0.2602 - lr: 1.0000e-05\n",
      "Epoch 7/20\n",
      "143/143 [==============================] - 95s 667ms/step - loss: 0.0656 - accuracy: 0.2603 - val_loss: 0.0629 - val_accuracy: 0.2602 - lr: 1.0000e-05\n",
      "Epoch 8/20\n",
      "143/143 [==============================] - 96s 669ms/step - loss: 0.0608 - accuracy: 0.2598 - val_loss: 0.0589 - val_accuracy: 0.2602 - lr: 1.0000e-05\n",
      "Epoch 9/20\n",
      "143/143 [==============================] - 96s 670ms/step - loss: 0.0574 - accuracy: 0.2596 - val_loss: 0.0561 - val_accuracy: 0.2605 - lr: 1.0000e-05\n",
      "Epoch 10/20\n",
      "143/143 [==============================] - 96s 672ms/step - loss: 0.0550 - accuracy: 0.2592 - val_loss: 0.0540 - val_accuracy: 0.2603 - lr: 1.0000e-05\n",
      "Epoch 11/20\n",
      "143/143 [==============================] - 96s 673ms/step - loss: 0.0532 - accuracy: 0.2602 - val_loss: 0.0525 - val_accuracy: 0.2603 - lr: 1.0000e-05\n",
      "Epoch 12/20\n",
      "143/143 [==============================] - 96s 670ms/step - loss: 0.0519 - accuracy: 0.2603 - val_loss: 0.0513 - val_accuracy: 0.2606 - lr: 1.0000e-05\n",
      "Epoch 13/20\n",
      "143/143 [==============================] - 96s 670ms/step - loss: 0.0509 - accuracy: 0.2601 - val_loss: 0.0504 - val_accuracy: 0.2602 - lr: 1.0000e-05\n",
      "Epoch 14/20\n",
      "143/143 [==============================] - 96s 670ms/step - loss: 0.0500 - accuracy: 0.2595 - val_loss: 0.0497 - val_accuracy: 0.2606 - lr: 1.0000e-05\n",
      "Epoch 15/20\n",
      "143/143 [==============================] - 97s 676ms/step - loss: 0.0494 - accuracy: 0.2601 - val_loss: 0.0491 - val_accuracy: 0.2604 - lr: 1.0000e-05\n",
      "Epoch 16/20\n",
      "143/143 [==============================] - 95s 664ms/step - loss: 0.0489 - accuracy: 0.2599 - val_loss: 0.0487 - val_accuracy: 0.2603 - lr: 1.0000e-05\n",
      "Epoch 17/20\n",
      "143/143 [==============================] - 97s 677ms/step - loss: 0.0485 - accuracy: 0.2590 - val_loss: 0.0483 - val_accuracy: 0.2604 - lr: 1.0000e-05\n",
      "Epoch 18/20\n",
      "143/143 [==============================] - 96s 675ms/step - loss: 0.0482 - accuracy: 0.2589 - val_loss: 0.0480 - val_accuracy: 0.2603 - lr: 1.0000e-05\n",
      "Epoch 19/20\n",
      "143/143 [==============================] - 96s 674ms/step - loss: 0.0479 - accuracy: 0.2604 - val_loss: 0.0478 - val_accuracy: 0.2605 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "143/143 [==============================] - 97s 680ms/step - loss: 0.0476 - accuracy: 0.2587 - val_loss: 0.0476 - val_accuracy: 0.2606 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "# history = model.fit(\n",
    "#     X_eeg,\n",
    "#     y_input_ids,\n",
    "#     verbose = 1,\n",
    "#     sample_weight=y_attention_mask.numpy(),\n",
    "#     epochs=20,\n",
    "#     batch_size=32,\n",
    "#     validation_split=0.25,\n",
    "#     callbacks=callbacks\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (swin)",
   "language": "python",
   "name": "swin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
